# rss/fetch_rss.py

import os
import feedparser
import json
from datetime import datetime, timezone
from typing import Dict, List
import hashlib
import re
import sys

# --- 1. å…¨å±€é…ç½® ---

# -- ç‹¬ç«‹çš„å¤§ç±»é…ç½® --
# å®šä¹‰æ¯ä¸ªçˆ¶ç±»è‡ªå·±çš„å±æ€§ï¼Œå¦‚é€šç”¨çš„å›¾æ ‡å’Œé¢œè‰²ã€‚
CATEGORIES = {
    "æŠ€æœ¯": {
        "icon": "ğŸ’»",  # ä»£è¡¨â€œæŠ€æœ¯â€å¤§ç±»çš„é€šç”¨å›¾æ ‡
        "color": "#4A90E2"
    },
    "å·¥ä½œ": {
        "icon": "ğŸ¢",
        "color": "#50C878"
    },
    "èµ„è®¯": {
        "icon": "ğŸŒ",
        "color": "#FF6B6B"
    }
}

# -- RSS æºï¼ˆå­ç±»ï¼‰é…ç½® --
# 'category' å­—æ®µå…³è”åˆ°ä¸Šé¢çš„ CATEGORIESã€‚
# 'icon' å­—æ®µæ˜¯æ¯ä¸ª RSS æºè‡ªå·±ç‹¬ç‰¹çš„å›¾æ ‡ã€‚
RSS_FEEDS = {
    "V2EXæŠ€æœ¯ä¸“åŒº": {
        "url": "https://www.v2ex.com/feed/tab/tech.xml",
        "category": "æŠ€æœ¯", # å…³è”åˆ° CATEGORIES["æŠ€æœ¯"]
        "icon": "ğŸ”§",     # æºæœ¬èº«çš„å›¾æ ‡
        "color": "#A5B4FC", # å¯ä»¥ä¸ºå­ç±»å®šä¹‰ä¸åŒçš„é¢œè‰²
        "description": "V2EXæŠ€æœ¯è®¨è®ºåŒº"
    },
    "ç¾å›¢æŠ€æœ¯å›¢é˜Ÿ": {
        "url": "https://tech.meituan.com/feed/",
        "category": "æŠ€æœ¯", # å…³è”åˆ° CATEGORIES["æŠ€æœ¯"]
        "icon": "ğŸš€",     # æºæœ¬èº«çš„å›¾æ ‡
        "color": "#FFD93D",
        "description": "ç¾å›¢æŠ€æœ¯å›¢é˜Ÿåšå®¢"
    },
    "V2EXé…·å·¥ä½œ": {
        "url": "https://www.v2ex.com/feed/tab/jobs.xml",
        "category": "å·¥ä½œ",
        "icon": "ğŸ’¼",
        "color": "#A7F3D0",
        "description": "V2EXæ‹›è˜ä¿¡æ¯"
    },
    "æ½®æµå‘¨åˆŠ": {
        "url": "https://weekly.tw93.fun/rss.xml",
        "category": "èµ„è®¯",
        "icon": "ğŸ“°",
        "color": "#FCA5A5",
        "description": "å‰ç«¯æ½®æµæŠ€æœ¯å‘¨åˆŠ"
    }
}

# -- å…¶ä»–è®¾ç½® --
MAX_ENTRIES_LIMIT = 200
ENTRIES_PER_PAGE = 20
BALANCE_STRATEGIES = {
    "equal": "å¹³å‡åˆ†é…",
    "weighted": "æŒ‰æƒé‡åˆ†é…",
    "dynamic": "åŠ¨æ€åˆ†é…ï¼ˆåŸºäºæ´»è·ƒåº¦ï¼‰"
}
RSS_WEIGHTS = {
    "V2EXæŠ€æœ¯ä¸“åŒº": 3,
    "ç¾å›¢æŠ€æœ¯å›¢é˜Ÿ": 3,
    "V2EXé…·å·¥ä½œ": 2,
    "æ½®æµå‘¨åˆŠ": 2
}


# --- 2. è¾…åŠ©å‡½æ•° ---

def get_output_path():
    """è®¡ç®—å¹¶è¿”å›JSONæ–‡ä»¶çš„ç»å¯¹è·¯å¾„"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir)
    data_dir = os.path.join(project_root, 'data')
    if not os.path.exists(data_dir):
        os.makedirs(data_dir)
    return os.path.join(data_dir, 'friends_feed.json')

def parse_date(date_string):
    """è§£æå¤šç§æ—¥æœŸæ ¼å¼"""
    formats = [
        "%a, %d %b %Y %H:%M:%S %z", "%a, %d %b %Y %H:%M:%S %Z",
        "%Y-%m-%dT%H:%M:%S%z", "%Y-%m-%dT%H:%M:%S.%f%z",
    ]
    for fmt in formats:
        try:
            if ":" == date_string[-3:-2]:
                date_string = date_string[:-3] + date_string[-2:]
            return datetime.strptime(date_string, fmt)
        except ValueError:
            pass
    print(f"è­¦å‘Šï¼šæ— æ³•è§£ææ—¥æœŸ '{date_string}'")
    return datetime(1970, 1, 1, tzinfo=timezone.utc)

def generate_entry_id(link: str) -> str:
    """ä¸ºæ–‡ç« ç”Ÿæˆå”¯ä¸€ID"""
    return hashlib.md5(link.encode()).hexdigest()[:12]

def calculate_equal_allocation(feed_count: int, total_limit: int) -> Dict[str, int]:
    """ç­‰é‡åˆ†é…ç­–ç•¥"""
    if feed_count == 0: return {}
    base_allocation = total_limit // feed_count
    remaining = total_limit % feed_count
    allocation = {}
    feeds = list(RSS_FEEDS.keys())
    for i, feed_name in enumerate(feeds):
        allocation[feed_name] = base_allocation + (1 if i < remaining else 0)
    return allocation

def calculate_weighted_allocation(total_limit: int) -> Dict[str, int]:
    """æƒé‡åˆ†é…ç­–ç•¥"""
    total_weight = sum(RSS_WEIGHTS.values())
    if total_weight == 0: return {feed: 0 for feed in RSS_FEEDS.keys()}
    allocation = {}
    allocated_total = 0
    feeds = list(RSS_FEEDS.keys())
    for i, feed_name in enumerate(feeds):
        if i == len(feeds) - 1:
            allocation[feed_name] = total_limit - allocated_total
        else:
            weight = RSS_WEIGHTS.get(feed_name, 1)
            allocated = int((weight / total_weight) * total_limit)
            allocation[feed_name] = allocated
            allocated_total += allocated
    return allocation

def calculate_dynamic_allocation(existing_entries: List[dict], total_limit: int) -> Dict[str, int]:
    """åŠ¨æ€åˆ†é…ç­–ç•¥"""
    feed_counts = {feed_name: 0 for feed_name in RSS_FEEDS.keys()}
    for entry in existing_entries:
        blog_name = entry.get("blog_name")
        if blog_name in feed_counts:
            feed_counts[blog_name] += 1
    total_existing = sum(feed_counts.values())
    if total_existing == 0:
        return calculate_equal_allocation(len(RSS_FEEDS), total_limit)
    allocation = {}
    allocated_total = 0
    feeds = list(RSS_FEEDS.keys())
    for i, feed_name in enumerate(feeds):
        if i == len(feeds) - 1:
            allocation[feed_name] = total_limit - allocated_total
        else:
            ratio = max(feed_counts[feed_name] / total_existing, 0.1) # ä¿è¯æœ€ä½æ¯”ä¾‹
            allocated = int(ratio * total_limit)
            allocation[feed_name] = allocated
            allocated_total += allocated
    return allocation

def get_allocation_strategy(existing_entries: List[dict], strategy: str) -> Dict[str, int]:
    """æ ¹æ®ç­–ç•¥è¿”å›æ¯ä¸ªRSSæºçš„æ–‡ç« é…é¢"""
    if strategy == "equal":
        return calculate_equal_allocation(len(RSS_FEEDS), MAX_ENTRIES_LIMIT)
    elif strategy == "weighted":
        return calculate_weighted_allocation(MAX_ENTRIES_LIMIT)
    elif strategy == "dynamic":
        return calculate_dynamic_allocation(existing_entries, MAX_ENTRIES_LIMIT)
    else:
        print(f"æœªçŸ¥ç­–ç•¥ '{strategy}'ï¼Œä½¿ç”¨é»˜è®¤çš„åŠ¨æ€åˆ†é…ç­–ç•¥")
        return calculate_dynamic_allocation(existing_entries, MAX_ENTRIES_LIMIT)

def fetch_feed_entries(blog_name: str, feed_config: dict, max_entries: int) -> List[dict]:
    """æŠ“å–å•ä¸ªRSSæºçš„æ–‡ç« """
    entries = []
    feed_url = feed_config["url"]
    try:
        print(f"  å¤„ç†ä¸­: {blog_name} (é…é¢: {max_entries})")
        feed = feedparser.parse(feed_url)
        if feed.bozo:
            print(f"    -> è­¦å‘Š: '{blog_name}' RSS æºå¯èƒ½æ ¼å¼ä¸æ­£ç¡®ã€‚")
        
        feed_entries = sorted(feed.entries, key=lambda x: parse_date(x.get("published", x.get("updated", ""))), reverse=True)
        
        for entry in feed_entries[:max_entries]:
            published_str = entry.get("published", entry.get("updated"))
            if not published_str: continue
            
            dt_object = parse_date(published_str)
            summary = re.sub(r'<[^>]+>', '', entry.get("summary", "")).strip()[:200]
            
            entries.append({
                "id": generate_entry_id(entry.link),
                "blog_name": blog_name, "title": entry.title, "link": entry.link,
                "published": dt_object.isoformat(), "timestamp": int(dt_object.timestamp()),
                "summary": summary, "category": feed_config.get("category", "å…¶ä»–"),
                "source_icon": feed_config.get("icon", "ğŸ“„"), "source_color": feed_config.get("color", "#666666")
            })
        print(f"    -> æˆåŠŸæŠ“å– {len(entries)} ç¯‡æ–‡ç« ")
    except Exception as e:
        print(f"    -> é”™è¯¯: æŠ“å– '{blog_name}' æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    return entries

# --- 3. ä¸»å‡½æ•° ---

def main(strategy: str):
    output_path = get_output_path()
    
    # æ­¥éª¤ 1: è¯»å–å†å²æ•°æ®
    print("--- 1. æ­£åœ¨è¯»å–å†å²æ•°æ®... ---")
    existing_entries, existing_links = [], set()
    if os.path.exists(output_path):
        try:
            with open(output_path, 'r', encoding='utf-8') as f:
                old_data = json.load(f)
                existing_entries = old_data.get('articles', [])
                existing_links = {e.get('link') for e in existing_entries if e.get('link')}
            print(f"æˆåŠŸåŠ è½½ {len(existing_entries)} æ¡å†å²æ–‡ç« ã€‚")
        except (json.JSONDecodeError, IOError) as e:
            print(f"è­¦å‘Š: è¯»å–æˆ–è§£ææ—§æ•°æ®æ–‡ä»¶å¤±è´¥: {e}")

    # æ­¥éª¤ 2: è®¡ç®—åˆ†é…ç­–ç•¥
    print(f"\n--- 2. è®¡ç®—è´Ÿè½½å‡è¡¡åˆ†é… (ç­–ç•¥: {BALANCE_STRATEGIES.get(strategy, strategy)}) ---")
    allocation = get_allocation_strategy(existing_entries, strategy)
    print("åˆ†é…ç»“æœ:")
    for name, count in allocation.items(): print(f"  {name}: {count} ç¯‡")
    
    # æ­¥éª¤ 3: æŠ“å–æ–°æ•°æ®
    print(f"\n--- 3. æ­£åœ¨æŠ“å–RSS feeds... ---")
    all_new_entries = []
    for name, config in RSS_FEEDS.items():
        if allocation.get(name, 0) > 0:
            all_new_entries.extend(fetch_feed_entries(name, config, allocation[name]))
    print(f"æ€»å…±æŠ“å–åˆ° {len(all_new_entries)} ç¯‡æ–‡ç« ã€‚")
    
    # æ­¥éª¤ 4: åˆå¹¶ä¸å»é‡
    print("\n--- 4. å»é‡ä¸åˆå¹¶... ---")
    combined_entries = {e['link']: e for e in existing_entries}
    new_count = 0
    for entry in all_new_entries:
        if entry['link'] not in combined_entries:
            new_count += 1
        combined_entries[entry['link']] = entry

    # æ’åºå¹¶æˆªæ–­
    final_entries = sorted(combined_entries.values(), key=lambda x: x.get('timestamp', 0), reverse=True)
    final_entries = final_entries[:MAX_ENTRIES_LIMIT]
    print(f"æ–°å¢ {new_count} ç¯‡æ–‡ç« ï¼Œæœ€ç»ˆå…± {len(final_entries)} ç¯‡ã€‚")
    
    # æ­¥éª¤ 5: ç”Ÿæˆå…ƒæ•°æ®
    # 1. ç›´æ¥ä»ç‹¬ç«‹çš„ CATEGORIES é…ç½®åˆå§‹åŒ–çˆ¶ç±»ç»“æ„
    categories_meta = {}
    for cat_name, cat_config in CATEGORIES.items():
        categories_meta[cat_name] = {
            "icon": cat_config.get("icon", "ğŸ“"), "color": cat_config.get("color", "#666666"),
            "count": 0, "sources": {}
        }
    
    # 2. è®¡ç®—æ¯ä¸ª RSS æºçš„æ–‡ç« æ•°é‡
    source_counts = {name: 0 for name in RSS_FEEDS.keys()}
    for entry in final_entries:
        if entry.get('blog_name') in source_counts:
            source_counts[entry['blog_name']] += 1
    
    # 3. å°† RSS æºä¿¡æ¯å¡«å……åˆ°å¯¹åº”çš„çˆ¶ç±»ä¸‹
    for source_name, source_config in RSS_FEEDS.items():
        category_name = source_config.get('category')
        if category_name in categories_meta:
            categories_meta[category_name]['sources'][source_name] = {
                "icon": source_config.get("icon", "ğŸ“„"), "color": source_config.get("color", "#888888"),
                "description": source_config.get("description", ""), "count": source_counts.get(source_name, 0)
            }
            categories_meta[category_name]['count'] += source_counts.get(source_name, 0)

    # æ„å»ºæœ€ç»ˆè¾“å‡ºæ•°æ®
    output_data = {
        "meta": {
            "total_articles": len(final_entries), "last_updated": datetime.now(timezone.utc).isoformat(),
            "entries_per_page": ENTRIES_PER_PAGE, "categories": categories_meta
        },
        "articles": final_entries
    }
    
    # æ­¥éª¤ 6: å†™å…¥æ–‡ä»¶
    print("\n--- 5. ä¿å­˜åˆ°æ–‡ä»¶... ---")
    try:
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        print(f"æˆåŠŸï¼{len(final_entries)} ç¯‡æ–‡ç« å·²ä¿å­˜åˆ°: {output_path}")
        
        print("\n--- æœ€ç»ˆç»Ÿè®¡ ---")
        for cat, info in categories_meta.items():
            if info['count'] > 0:
                print(f"  {info['icon']} {cat}: {info['count']} ç¯‡")
                for src, s_info in info['sources'].items():
                    if s_info['count'] > 0:
                        print(f"    - {s_info['icon']} {src}: {s_info['count']} ç¯‡")
            
    except IOError as e:
        print(f"é”™è¯¯ï¼æ— æ³•å†™å…¥æ–‡ä»¶: {e}")

# --- 4. è„šæœ¬æ‰§è¡Œå…¥å£ ---

if __name__ == "__main__":
    strategy_arg = "dynamic"
    if len(sys.argv) > 1 and sys.argv[1] in BALANCE_STRATEGIES:
        strategy_arg = sys.argv[1]
    
    print(f"ä½¿ç”¨è´Ÿè½½å‡è¡¡ç­–ç•¥: {BALANCE_STRATEGIES.get(strategy_arg, 'æœªçŸ¥')}")
    print("=" * 60)
    
    main(strategy_arg)